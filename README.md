# NLP Data Loading and Tokenization
This repository contains Jupyter Notebook files demonstrating:
## Description
1.  Creating an NLP Data Loader:  
    Implements a custom data loader for NLP tasks, handling text data and preprocessing steps.          
2.  Implementing Tokenization v2:
    Explores advanced tokenization techniques, such as subword tokenization, using libraries like Hugging Face Transformers.


## License

[IBM](https://www.coursera.org/learn/generative-ai-llm-architecture-data-preparation/)

